{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNLDLcbBRZUIsxbaGf9fFYP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Simo56a0/machineLEARNING/blob/master/capsnets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KViNzRKsmZhK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63a24ee-6b0e-4f47-c2f4-9ed8248e8c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update dataset paths\n",
        "BASE_PATH = \"/content/drive/MyDrive/DATASET_ug_sign_language/\"\n",
        "VIDEO_PATH = \"/content/drive/MyDrive/DATASET_ug_sign_language/videos/\"\n",
        "FRAMES_PATH = \"/content/drive/MyDrive/DATASET_ug_sign_language/frames1\"\n",
        "ANNOTATIONS_PATH = \"/content/drive/MyDrive/DATASET_ug_sign_language/encoded_sign_labels.csv\"\n"
      ],
      "metadata": {
        "id": "-NJekt6i5Rww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python tensorflow-addons\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3oyeRyI5rud",
        "outputId": "03ded08b-6ada-4feb-bde4-19f34beb601e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (24.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.2\n",
            "    Uninstalling typeguard-4.4.2:\n",
            "      Successfully uninstalled typeguard-4.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.5.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crvvPwmY5y4N",
        "outputId": "c6942047-ed02-473c-c66b-c35b80302198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Verify dataset\n",
        "print(\"Files in Frames Folder: \", os.listdir(FRAMES_PATH)[:10])\n",
        "print(\"Files in Videos Folder: \", os.listdir(VIDEO_PATH)[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEGL7PZY54d1",
        "outputId": "1d0019d2-435f-4ec1-9260-a7fdca0b2c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in Frames Folder:  ['0060.mp4_frame_32.jpg', '0060.mp4_frame_33.jpg', '0061.mp4_frame_0.jpg', '0061.mp4_frame_1.jpg', '0061.mp4_frame_2.jpg', '0061.mp4_frame_3.jpg', '0061.mp4_frame_4.jpg', '0061.mp4_frame_5.jpg', '0061.mp4_frame_6.jpg', '0061.mp4_frame_7.jpg']\n",
            "Files in Videos Folder:  ['0066.mp4', '0068.mp4', '0067.mp4', '0069.mp4', '0070.mp4', '0071.mp4', '0072.mp4', '0073.mp4', '0074.mp4', '0075.mp4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "R8dBY0hn6Y7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def load_data(frames_path, df, img_size=(64, 64)):\n",
        "    X, Y = [], []\n",
        "    missing_files = 0\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        label = row['encoded_label']\n",
        "        video_id = row['video_ID']\n",
        "\n",
        "        # Look for multiple frames for a given video\n",
        "        frame_files = [f for f in os.listdir(frames_path) if f.startswith(f\"{video_id}_frame_\")]\n",
        "\n",
        "        if frame_files:\n",
        "            for frame_file in frame_files:\n",
        "                frame_path = os.path.join(frames_path, frame_file)\n",
        "\n",
        "                img = cv2.imread(frame_path)\n",
        "                if img is None:\n",
        "                    missing_files += 1\n",
        "                    print(f\"Corrupt file: {frame_path}\")  # Debugging\n",
        "                    continue\n",
        "\n",
        "                img = cv2.resize(img, img_size)\n",
        "                img = img / 255.0  # Normalize\n",
        "                X.append(img)\n",
        "                Y.append(label)\n",
        "        else:\n",
        "            missing_files += 1\n",
        "            print(f\"Missing frames for video: {video_id}\")\n",
        "\n",
        "    print(f\"Total Missing or Corrupt Files: {missing_files}\")  # Debugging\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "df = pd.read_csv(ANNOTATIONS_PATH)\n",
        "X, Y = load_data(FRAMES_PATH, df)\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}, Labels: {Y.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgTHtztg6IK7",
        "outputId": "debfcffc-4f8a-47a1-cac5-fb0e4d3c3f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Missing or Corrupt Files: 0\n",
            "Dataset shape: (4247, 64, 64, 3), Labels: (4247,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load annotations\n",
        "df = pd.read_csv(ANNOTATIONS_PATH)\n",
        "\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"First 5 rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing Values:\", df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_ntCHfv84t9",
        "outputId": "ab037693-3714-4b84-bca9-b8149e912874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (90, 2)\n",
            "First 5 rows:\n",
            "   video_ID sign_word\n",
            "0  0001.mp4     hello\n",
            "1  0002.mp4       you\n",
            "2  0003.mp4       how\n",
            "3  0004.mp4      name\n",
            "4  0005.mp4      what\n",
            "Missing Values: video_ID     0\n",
            "sign_word    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use stratified splitting\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=42)\n",
        "\n",
        "print(f\"Training: {X_train.shape}, Testing: {X_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUwAJyf2DuTU",
        "outputId": "a249b3ce-4795-43e5-9e18-1a5a1fd7fc5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: (3397, 64, 64, 3), Testing: (850, 64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)\n"
      ],
      "metadata": {
        "id": "bsdHSlmGDzEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Reshape, Lambda, Dense, Input, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Squash function (with epsilon for stability)\n",
        "def squash(vectors, axis=-1):\n",
        "    epsilon = 1e-7  # Increase epsilon for better stability\n",
        "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm + epsilon)\n",
        "    return scale * vectors / (tf.sqrt(s_squared_norm + epsilon))\n",
        "\n",
        "# Updated CapsuleLayer with routing logits clipping\n",
        "class CapsuleLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_capsules, dim_capsule, num_routing=3, **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsules = num_capsules\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.num_routing = num_routing\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # input_shape: (batch_size, input_capsules, input_dim)\n",
        "        self.input_capsules = input_shape[1]\n",
        "        self.input_dim = input_shape[2]\n",
        "        # Weight matrix: shape (input_capsules, num_capsules, dim_capsule, input_dim)\n",
        "        self.W = self.add_weight(\n",
        "            shape=(self.input_capsules, self.num_capsules, self.dim_capsule, self.input_dim),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True,\n",
        "            name='W'\n",
        "        )\n",
        "        super(CapsuleLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # inputs: (batch_size, input_capsules, input_dim)\n",
        "        inputs_expanded = tf.expand_dims(inputs, 2)  # (batch_size, input_capsules, 1, input_dim)\n",
        "        inputs_expanded = tf.expand_dims(inputs_expanded, -1)  # (batch_size, input_capsules, 1, input_dim, 1)\n",
        "        inputs_tiled = tf.tile(inputs_expanded, [1, 1, self.num_capsules, 1, 1])  # (batch_size, input_capsules, num_capsules, input_dim, 1)\n",
        "\n",
        "        # Expand W: shape becomes (1, input_capsules, num_capsules, dim_capsule, input_dim)\n",
        "        W_tiled = tf.expand_dims(self.W, 0)\n",
        "        # Compute u_hat via matrix multiplication: result shape (batch_size, input_capsules, num_capsules, dim_capsule, 1)\n",
        "        u_hat = tf.matmul(W_tiled, inputs_tiled)\n",
        "        u_hat = tf.squeeze(u_hat, axis=-1)  # (batch_size, input_capsules, num_capsules, dim_capsule)\n",
        "\n",
        "        # Initialize routing logits b to zeros.\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        b = tf.zeros(shape=(batch_size, self.input_capsules, self.num_capsules))\n",
        "\n",
        "        # Routing algorithm\n",
        "        for i in range(self.num_routing):\n",
        "            # Clip b to prevent extremely high or low values, then compute softmax\n",
        "            c = tf.nn.softmax(tf.clip_by_value(b, -10.0, 10.0), axis=2)  # (batch_size, input_capsules, num_capsules)\n",
        "            c_expanded = tf.expand_dims(c, -1)  # (batch_size, input_capsules, num_capsules, 1)\n",
        "            s = tf.reduce_sum(c_expanded * u_hat, axis=1)  # (batch_size, num_capsules, dim_capsule)\n",
        "            v = squash(s)\n",
        "            if i < self.num_routing - 1:\n",
        "                v_expanded = tf.expand_dims(v, 1)  # (batch_size, 1, num_capsules, dim_capsule)\n",
        "                b += tf.reduce_sum(u_hat * v_expanded, axis=-1)\n",
        "        return v  # (batch_size, num_capsules, dim_capsule)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.num_capsules, self.dim_capsule)\n",
        "\n",
        "# Build the Capsule Network model with an added pooling layer to reduce memory consumption\n",
        "def build_capsule_network(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # First Convolutional Layer\n",
        "    conv1 = Conv2D(256, (9, 9), strides=1, padding='valid')(inputs)\n",
        "    conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
        "    conv1 = tf.keras.layers.Activation('relu')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    # Primary Capsules: Convolutional layer followed by reshaping\n",
        "    primary_caps = Conv2D(32 * 8, (9, 9), strides=2, padding='valid')(pool1)\n",
        "    primary_caps = tf.keras.layers.BatchNormalization()(primary_caps)\n",
        "    primary_caps = tf.keras.layers.Activation('relu')(primary_caps)\n",
        "    primary_caps = Reshape((-1, 8))(primary_caps)\n",
        "    primary_caps = Lambda(squash)(primary_caps)\n",
        "\n",
        "    # Capsule Layer: one capsule per class\n",
        "    digit_caps = CapsuleLayer(num_classes, 16, num_routing=3)(primary_caps)\n",
        "\n",
        "    # Compute the length of each capsule vector to get class probabilities\n",
        "    outputs = Lambda(lambda z: tf.sqrt(tf.reduce_sum(tf.square(z), axis=-1)))(digit_caps)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Example usage:\n",
        "input_shape = (64, 64, 3)\n",
        "num_classes = len(df['encoded_label'].unique())  # Update according to your CSV\n",
        "model = build_capsule_network(input_shape, num_classes)\n",
        "\n",
        "# Use a lower learning rate and gradient clipping to enhance stability\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, clipnorm=0.5)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Then train with a reduced batch size if needed:\n",
        "# history = model.fit(datagen.flow(X_train, Y_train, batch_size=16),\n",
        "#                     validation_data=(X_test, Y_test),\n",
        "#                     epochs=50,\n",
        "#                     callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "RCrC7ydEKwPB",
        "outputId": "d529216a-c720-4998-9f79-7140739520f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │          \u001b[38;5;34m62,464\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │       \u001b[38;5;34m5,308,672\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3200\u001b[0m, \u001b[38;5;34m8\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda_6 (\u001b[38;5;33mLambda\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3200\u001b[0m, \u001b[38;5;34m8\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ capsule_layer_3 (\u001b[38;5;33mCapsuleLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m, \u001b[38;5;34m16\u001b[0m)              │      \u001b[38;5;34m34,816,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda_7 (\u001b[38;5;33mLambda\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">62,464</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,308,672</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ capsule_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CapsuleLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)              │      <span style=\"color: #00af00; text-decoration-color: #00af00\">34,816,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,189,184\u001b[0m (153.31 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,189,184</span> (153.31 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,188,160\u001b[0m (153.31 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,188,160</span> (153.31 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    datagen.flow(X_train, Y_train, batch_size=16),  # reduced batch size\n",
        "    validation_data=(X_test, Y_test),\n",
        "    epochs=20,\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmB37fBVD8gG",
        "outputId": "ed246721-7511-47a3-cc68-73c049426b47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - accuracy: 0.0478 - loss: 4.2220 - val_accuracy: 0.0447 - val_loss: 4.2083\n",
            "Epoch 2/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 96ms/step - accuracy: 0.0399 - loss: 4.2283 - val_accuracy: 0.0447 - val_loss: 4.2107\n",
            "Epoch 3/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - accuracy: 0.0431 - loss: 4.2169 - val_accuracy: 0.0447 - val_loss: 4.1977\n",
            "Epoch 4/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 96ms/step - accuracy: 0.0487 - loss: 4.2125 - val_accuracy: 0.0447 - val_loss: 4.1940\n",
            "Epoch 5/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 94ms/step - accuracy: 0.0465 - loss: 4.2093 - val_accuracy: 0.0447 - val_loss: 4.1992\n",
            "Epoch 6/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 96ms/step - accuracy: 0.0411 - loss: 4.1998 - val_accuracy: 0.0447 - val_loss: 4.1893\n",
            "Epoch 7/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 96ms/step - accuracy: 0.0444 - loss: 4.2057 - val_accuracy: 0.0447 - val_loss: 4.1847\n",
            "Epoch 8/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 96ms/step - accuracy: 0.0398 - loss: 4.2065 - val_accuracy: 0.0447 - val_loss: 4.1874\n",
            "Epoch 9/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - accuracy: 0.0484 - loss: 4.1950 - val_accuracy: 0.0447 - val_loss: 4.1786\n",
            "Epoch 10/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 95ms/step - accuracy: 0.0417 - loss: 4.2088 - val_accuracy: 0.0447 - val_loss: 4.1751\n",
            "Epoch 11/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 95ms/step - accuracy: 0.0450 - loss: 4.1908 - val_accuracy: 0.0447 - val_loss: 4.1766\n",
            "Epoch 12/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 96ms/step - accuracy: 0.0465 - loss: 4.1921 - val_accuracy: 0.0447 - val_loss: 4.1782\n",
            "Epoch 13/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - accuracy: 0.0421 - loss: 4.1952 - val_accuracy: 0.0447 - val_loss: 4.1672\n",
            "Epoch 14/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 94ms/step - accuracy: 0.0479 - loss: 4.1784 - val_accuracy: 0.0318 - val_loss: 4.2351\n",
            "Epoch 15/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 94ms/step - accuracy: 0.0494 - loss: 4.1871 - val_accuracy: 0.0447 - val_loss: 4.1689\n",
            "Epoch 16/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - accuracy: 0.0442 - loss: 4.1824 - val_accuracy: 0.0447 - val_loss: 4.1601\n",
            "Epoch 17/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 94ms/step - accuracy: 0.0436 - loss: 4.1705 - val_accuracy: 0.0447 - val_loss: 4.1872\n",
            "Epoch 18/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 95ms/step - accuracy: 0.0381 - loss: 4.1709 - val_accuracy: 0.0447 - val_loss: 4.1791\n",
            "Epoch 19/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 94ms/step - accuracy: 0.0496 - loss: 4.1699 - val_accuracy: 0.0447 - val_loss: 4.1666\n",
            "Epoch 20/20\n",
            "\u001b[1m213/213\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 95ms/step - accuracy: 0.0431 - loss: 4.1754 - val_accuracy: 0.0447 - val_loss: 4.1511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Accuracy & Loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Accuracy Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy')\n",
        "\n",
        "# Loss Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "e6zUSmjdD_nI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}